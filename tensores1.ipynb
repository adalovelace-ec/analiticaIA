{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b327d231",
   "metadata": {},
   "source": [
    "Código para explorar tensores en pytorch\n",
    "\n",
    "Para instalar pytorch y los otros paquetes matemáticos:\n",
    "\n",
    "conda install pytorch cpuonly -c pytorch\n",
    "conda install pandas numpy matplotlib seaborn\n",
    "\n",
    "opción \"-c\" es para definir el canal desde donde se descarga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae608eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12238901",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  https://pytorch.org/docs/stable/index.html\n",
    "\n",
    "\n",
    "\n",
    "x = torch.ones(2,2, dtype = torch.int)   #torch.float16 \n",
    "print(x)\n",
    "print('tipo del tensor',x.dtype)\n",
    "print(x.size())\n",
    "\n",
    "y = torch.rand(2,2)\n",
    "# suma, producto y división, elemento por elemento\n",
    "print(x+y)\n",
    "print(x*y)\n",
    "z = x/y-torch.div(x,y)\n",
    "print(z)\n",
    "\n",
    "x = torch.empty(2,2,2,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd706cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])  # x tiene shape (2, 3), total 6 elementos\n",
    "y = x.view(6)  # y tendrá shape (6,)\n",
    "print(y)  # tensor([1, 2, 3, 4, 5, 6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063f4cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])  # shape (2, 3), total 6 elementos\n",
    "w = x.view(3, -1)  # PyTorch calcula la segunda dimensión para que 3 * ? = 6 -> ? = 2\n",
    "print(w)\n",
    "# tensor([[1, 2],\n",
    "#         [3, 4],\n",
    "#         [5, 6]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687d029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2,3)\n",
    "print(f'despliegue parcial del tensor {x[:,2]}')\n",
    "\n",
    "print(f'me da el valor, como escalar, de dimension 1 {x[0,1].item()}')\n",
    "#.item() convierte ese tensor escalar (tensor de dimensión 0) en un valor numérico de Python (float)\n",
    "print(type(x[0,1].item()))  # <class 'float'>\n",
    "\n",
    "print(f'distinto a {x[0,1]} ?')\n",
    "print(f'tipo de x {type(x[0,1])}')\n",
    "\n",
    "# de elemento numpy a tensor de PyTorch\n",
    "a = np.ones(5)\n",
    "b= torch.from_numpy(a)\n",
    "\n",
    "print(b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ad7bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2,3)\n",
    "y = x.view(6)\n",
    "w = x.view(3, -1)\n",
    "xx = x.numpy()\n",
    "\n",
    "# view() cambia la forma del tensor sin copiar los datos, creando una vista del tensor original.\n",
    "# y = x.view(6) convierte x en un tensor 1D de 6 elementos.\n",
    "# w = x.view(3, -1) reorganiza x en una matriz con 3 filas y el número de columnas que PyTorch \n",
    "# calcule automáticamente para mantener el mismo número total de elementos.\n",
    "#view() solo funciona si el tensor es contiguo en memoria. Si no, hay que usar .contiguous() antes.\n",
    "# Un tensor es contiguo si sus elementos están almacenados de forma secuencial en memoria, \n",
    "# siguiendo el orden natural del tensor (por ejemplo, fila por fila en un tensor 2D).\n",
    "\n",
    "#  Compartición de memoria entre tensores (herencia de datos)\n",
    "\n",
    "print(f'x antes de la adicion {x}')\n",
    "print(f'xx -x.numpy- antes de la adición en x {xx}')\n",
    "print(f'y -x.view antes de la adición en x {y}')\n",
    "\n",
    "x.add_(3)\n",
    "\n",
    "print(\"\")\n",
    "print(\"los hijos heredan del padre\")\n",
    "print(f'x después de la adicion en x {x}')\n",
    "print(f'xx -x.numpy- después de la adición en x {xx}')\n",
    "print(f'y -x.view - después de la adición en x {y}')\n",
    "\n",
    "print(\"\")\n",
    "print(\"los padres heredan de los hijos\")\n",
    "\n",
    "y.add_(5)\n",
    "\n",
    "print(f'x después de la adicion en y {x}')\n",
    "print(f'xx -x.numpy- después de la adición en y {xx}')\n",
    "print(f'y -x.view - después de la adición en y {y}')\n",
    "\n",
    "print(\"\")\n",
    "print(\"se rompen las herencias\")\n",
    "y= y+10\n",
    "print(f'x después de y+1 {x}')\n",
    "print(f'xx -x.numpy- después de y+1 {xx}')\n",
    "print(f'y -x.view - después de y+1 {y}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfce319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# la misma lógica pero cambiando sólo elementos\n",
    "\n",
    "xx = torch.tensor([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "# Reshape the tensor\n",
    "yy = xx.view(2, 3)\n",
    "\n",
    "# Change a value in xx\n",
    "xx[0] = 10\n",
    "\n",
    "# Both xx and yy reflect the change\n",
    "print(\"xx:\", xx)\n",
    "print(\"yy:\", yy)\n",
    "\n",
    "# Change a value in yy\n",
    "yy[0, 1] = 20\n",
    "\n",
    "# Both xx and yy reflect the change\n",
    "print(\"xx after modifying yy:\", xx)\n",
    "print(\"yy after modifying yy:\", yy)\n",
    "\n",
    "# finalmente, si se quiere romper la herencia de datos, se puede usar .clone() o .detach()\n",
    "# .clone() crea una copia del tensor, mientras que .detach() crea un nuevo tensor\n",
    "# que comparte los mismos datos pero no está conectado al grafo de autograd.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e9ee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#para calcular el gradiente de un tensor, se debe establecer requires_grad=True\n",
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(f'x con gradiente {x}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d66040a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "x is on: cpu\n",
      "y is on: cpu\n",
      "z is on: cpu\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "# we can handle where are the mathematical elements\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    x = torch.ones(5,device=device)\n",
    "    y = torch.ones(5)\n",
    "    y = y.to(device)\n",
    "    z = x + y\n",
    "    z = z.to(\"cpu\")\n",
    "\n",
    "print(f\"x is on: {x.device}\")\n",
    "print(f\"y is on: {y.device}\")\n",
    "print(f\"z is on: {z.device}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_net1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
