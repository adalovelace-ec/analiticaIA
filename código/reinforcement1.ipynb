{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4b4cd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition Probability Matrices:\n",
      "P[accion=0]:\n",
      " [[0.43100234 0.02562935 0.54336831]\n",
      " [0.36704318 0.35443418 0.27852264]\n",
      " [0.18214073 0.55116157 0.2666977 ]]\n",
      "\n",
      "P[accion=1]:\n",
      " [[0.18829064 0.43831235 0.37339701]\n",
      " [0.16163858 0.61683809 0.22152333]\n",
      " [0.36808894 0.40026078 0.23165029]]\n",
      "\n",
      "P[accion=2]:\n",
      " [[0.5914001  0.0556396  0.35296029]\n",
      " [0.11066639 0.72570517 0.16362843]\n",
      " [0.13386426 0.62820766 0.23792809]]\n",
      "\n",
      "\n",
      "Reward Matrix R:\n",
      "[[0.21389137 0.44061241 0.69965257]\n",
      " [0.93557497 0.40348645 1.28081345]\n",
      " [0.96613967 1.01047344 0.7737853 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(2)\n",
    "\n",
    "# Define number of states and actions\n",
    "n_states = 3\n",
    "n_actions = 3\n",
    "\n",
    "# Generate transition probability matrices P[a][s][s']\n",
    "P = np.zeros((n_actions, n_states, n_states))\n",
    "for a in range(n_actions):\n",
    "    for s in range(n_states):\n",
    "        row = np.random.rand(n_states)\n",
    "        P[a][s] = row / row.sum()  # normalize to make it a valid probability distribution\n",
    "\n",
    "# Transition matrices P[0], P[1], P[2]\n",
    "P_0 = P[0]\n",
    "P_1 = P[1]\n",
    "P_2 = P[2]\n",
    "\n",
    "# Generate reward matrix R[s][a], values in [0, 2]\n",
    "R = np.random.uniform(0, 2, size=(n_states, n_actions))\n",
    "\n",
    "print(\"Transition Probability Matrices:\")\n",
    "print(\"P[accion=0]:\\n\", P_0)\n",
    "print(\"\")\n",
    "print(\"P[accion=1]:\\n\", P_1)\n",
    "print(\"\")\n",
    "print(\"P[accion=2]:\\n\", P_2)\n",
    "print(\"\")\n",
    "\n",
    "print(\"\\nReward Matrix R:\")\n",
    "print(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2af2f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned Q* Table:\n",
      "Q(0,0) = 20.5011\tQ(0,1) = 20.8991\tQ(0,2) = 20.8529\t\n",
      "Q(1,0) = 21.2468\tQ(1,1) = 21.1205\tQ(1,2) = 21.7352\t\n",
      "Q(2,0) = 21.4309\tQ(2,1) = 21.3494\tQ(2,2) = 21.3218\t\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This code implements a simple Q-learning algorithm for a Markov Decision Process (MDP)\n",
    "# with randomly generated transition probabilities and rewards.\n",
    "\n",
    "# ---- Q-learning Parameters ----\n",
    "alpha = 0.1       # learning rate\n",
    "gamma = 0.95      # discount factor\n",
    "epsilon = 0.1    # exploration rate\n",
    "episodes = 10000\n",
    "max_steps = 500    # per episode\n",
    "\n",
    "# ---- Initialize Q-table ----\n",
    "Q = np.random.rand(n_states, n_actions)\n",
    "\n",
    "# ---- Q-learning Loop ----\n",
    "for episode in range(episodes):\n",
    "    s = np.random.randint(0, n_states)  # Start in random state\n",
    "\n",
    "    for _ in range(max_steps):\n",
    "        # ε-greedy action selection\n",
    "        if np.random.rand() < epsilon:\n",
    "            a = np.random.randint(0, n_actions)  # Explore\n",
    "        else:\n",
    "            a = np.argmax(Q[s])  # Exploit\n",
    "\n",
    "        # Sample next state s' from P[a][s]\n",
    "        s_prime = np.random.choice(n_states, p=P[a][s])\n",
    "        r = R[s, a]\n",
    "\n",
    "        # Q-value update\n",
    "        Q[s, a] += alpha * (r + gamma * np.max(Q[s_prime]) - Q[s, a])\n",
    "\n",
    "        s = s_prime  # Move to next state\n",
    "\n",
    "# ---- Output the learned Q* ----\n",
    "print(\"Learned Q* Table:\")\n",
    "for i in range(n_states):\n",
    "    for j in range(n_actions):\n",
    "        print(f\"Q({i},{j}) = {Q[i,j]:.4f}\", end=\"\\t\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17895b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Bellman equation for Q(1, 1):\n",
      "  Q*(1,1)        = 21.120473\n",
      "  R(1,1)         = 0.403486\n",
      "  Expected max Q(s') = 21.532680\n",
      "  RHS (Bellman)      = 20.859532\n",
      "  Difference         = 0.260940   as % of Q* = 1.24%\n"
     ]
    }
   ],
   "source": [
    "# --- PARAMETERS ---\n",
    "gamma = 0.95       # discount factor\n",
    "s = 1              # state index\n",
    "a = 1              # action index\n",
    "\n",
    "# --- Bellman Evaluation ---\n",
    "# Get reward\n",
    "r_sa = R[s, a]\n",
    "\n",
    "# Get transition probabilities for taking action a in state s\n",
    "p_s_prime = P[a][s]  # array of P(s' | s, a)\n",
    "\n",
    "# Compute max_a' Q(s', a') for each possible s'\n",
    "max_q_s_prime = np.max(Q, axis=1)  # array of size [n_states]\n",
    "\n",
    "# Compute expected future return: ∑ P(s'|s,a) * max_a' Q(s',a')\n",
    "expected_future_value = np.dot(p_s_prime, max_q_s_prime)\n",
    "\n",
    "# Bellman right-hand side\n",
    "rhs = r_sa + gamma * expected_future_value\n",
    "\n",
    "# Q* value (left-hand side)\n",
    "lhs = Q[s, a]\n",
    "\n",
    "# --- PRINT RESULTS ---\n",
    "print(f\"Checking Bellman equation for Q({s}, {a}):\")\n",
    "print(f\"  Q*({s},{a})        = {lhs:.6f}\")\n",
    "print(f\"  R({s},{a})         = {r_sa:.6f}\")\n",
    "print(f\"  Expected max Q(s') = {expected_future_value:.6f}\")\n",
    "print(f\"  RHS (Bellman)      = {rhs:.6f}\")\n",
    "print(f\"  Difference         = {lhs - rhs:.6f}   as % of Q* = {(lhs - rhs) / lhs * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_net1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
